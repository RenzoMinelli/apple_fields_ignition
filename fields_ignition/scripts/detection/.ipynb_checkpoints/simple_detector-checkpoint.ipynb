{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "from rospy import loginfo, logwarn, logerr\n",
    "import tf2_ros\n",
    "import tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sensor_msgs.msg import PointCloud2, PointField, Image\n",
    "from sensor_msgs import point_cloud2 as pc2\n",
    "from cv_bridge import CvBridge\n",
    "bridge = CvBridge()\n",
    "from matplotlib import pyplot as plt\n",
    "from geometry_msgs.msg import Point\n",
    "from std_msgs.msg import String\n",
    "from fields_ignition_msgs.msg import Detection, Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1667529355.253701, 47.356000]: running...\n",
      "param \"~image_topic\" = \"costar_husky_sensor_config_1/left/image_raw\"\n",
      "param \"~depth_topic\" = \"/costar_husky_sensor_config_1/front/depth/\"\n"
     ]
    }
   ],
   "source": [
    "rospy.init_node('simple_detector')\n",
    "loginfo('running...')\n",
    "tfBuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfBuffer)\n",
    "\n",
    "def get_param(name, default):\n",
    "    try:\n",
    "        value = rospy.get_param(name, default)\n",
    "    except ConnectionRefusedError:\n",
    "        value = default\n",
    "    print('param \"{}\" = \"{}\"'.format(name, value))\n",
    "    return value\n",
    "\n",
    "IMAGE_TOPIC = get_param('~image_topic', 'costar_husky_sensor_config_1/left/image_raw')\n",
    "DEPTH_TOPIC = get_param('~depth_topic', '/costar_husky_sensor_config_1/points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_detection = rospy.Publisher('/detections', Detections, queue_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchingMessageBuffer():\n",
    "    def __init__(self):\n",
    "        self.sub_img_msg = rospy.Subscriber(IMAGE_TOPIC, Image, self.handle_img)\n",
    "        self.sub_depth_msg = rospy.Subscriber(DEPTH_TOPIC, PointCloud2, self.handle_depth)\n",
    "        self.imgs = []\n",
    "        self.depths = []\n",
    "        self.max_buff = 5\n",
    "\n",
    "    def handle_img(self, img):\n",
    "        self.imgs.append(img)\n",
    "        self.imgs = self.imgs[-self.max_buff:]\n",
    "    \n",
    "    def handle_depth(self, depth):\n",
    "        self.depths.append(depth)\n",
    "        self.depths = self.depths[-self.max_buff:]\n",
    "\n",
    "    def get_next(self):\n",
    "        if not self.imgs or not self.depths:\n",
    "            return None, None\n",
    "            \n",
    "        def time_dist(img: Image, depth: PointCloud2):\n",
    "            return np.abs(img.header.stamp.to_time() - depth.header.stamp.to_time())\n",
    "        min_time_dist = float('inf')\n",
    "        pair = None\n",
    "        for img in self.imgs[::-1]:\n",
    "            for depth in self.depths[::-1]:\n",
    "                td = time_dist(img, depth)\n",
    "                if td < min_time_dist:\n",
    "                    min_time_dist = td\n",
    "                    pair = (img, depth)\n",
    "        self.imgs.remove(pair[0])\n",
    "        self.depths.remove(pair[1])\n",
    "        return pair\n",
    "\n",
    "mmbuff = MatchingMessageBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_detections(mask, depth):\n",
    "    x_cords, y_cords = np.mgrid[0:mask.shape[1], 0:mask.shape[0]].astype(np.int)\n",
    "    max_detect_dist = 3.0\n",
    "\n",
    "    mask = mask.T.reshape(-1).astype(np.bool)\n",
    "    if not mask.any():\n",
    "        return []\n",
    "    uvs = np.column_stack([x_cords.ravel(), y_cords.ravel()])[mask]\n",
    "    points = list(pc2.read_points(depth, field_names = (\"x\", \"y\", \"z\"), uvs=uvs.tolist()))\n",
    "    points = np.array(points)\n",
    "    dists = np.sqrt(np.sum(points ** 2, axis=1))\n",
    "    points = points[dists < max_detect_dist]\n",
    "    points = points[np.isfinite(points).all(axis=1)]\n",
    "    tf_cam = tfBuffer.lookup_transform('field', depth.header.frame_id, rospy.Time(), rospy.Duration(1.0))\n",
    "\n",
    "    t = tf.transformations\n",
    "    m_translation = t.translation_matrix([\n",
    "        tf_cam.transform.translation.x,\n",
    "        tf_cam.transform.translation.y,\n",
    "        tf_cam.transform.translation.z\n",
    "    ])\n",
    "    m_rotation = t.quaternion_matrix([\n",
    "        tf_cam.transform.rotation.x,\n",
    "        tf_cam.transform.rotation.y,\n",
    "        tf_cam.transform.rotation.z,\n",
    "        tf_cam.transform.rotation.w\n",
    "    ])\n",
    "    m_transform = t.concatenate_matrices(m_translation, m_rotation)\n",
    "\n",
    "    detections = []\n",
    "    for point in points:\n",
    "        pos = m_transform.dot(np.array([point[0], point[1], point[2], 1]))[0:3]\n",
    "        msg = Detection()\n",
    "        msg.position.pose.position.x = pos[0]\n",
    "        msg.position.pose.position.y = pos[1]\n",
    "        msg.position.pose.position.z = pos[2]\n",
    "        detections.append(msg)\n",
    "    return detections\n",
    "\n",
    "def detect():\n",
    "    img_msg, depth_msg = mmbuff.get_next()\n",
    "    if img_msg is None or depth_msg is None:\n",
    "        return\n",
    "    img = bridge.imgmsg_to_cv2(img_msg, desired_encoding='passthrough')\n",
    "\n",
    "    hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    lower_red = np.array([0,2,100])\n",
    "    upper_red = np.array([9,244,162])\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    # plt.imshow(mask)\n",
    "    detections = mask_to_detections(mask, depth_msg)\n",
    "    msg = Detections()\n",
    "    for d in detections:\n",
    "        msg.detections.append(d)\n",
    "    pub_detection.publish(msg)\n",
    "    \n",
    "detect()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    rate = rospy.Rate(10)\n",
    "    while not rospy.is_shutdown():\n",
    "        detect()\n",
    "        rate.sleep()\n",
    "except rospy.ROSInterruptException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
